import re
import logging
import httpx
from fastapi import FastAPI, HTTPException
from selenium import webdriver
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup

app = FastAPI()

# URL fixa do XML da imobili谩ria
XML_URL = "https://redeurbana.com.br/imoveis/rede/c6280d26-b925-405f-8aab-dd3afecd2c0b"

logging.basicConfig(level=logging.INFO)

# 1锔  Extrai URL de uma mensagem enviada pelo usu谩rio

@app.post("/extract-url/")
async def extract_url_from_message(message: str):
    """Extrai a URL de uma mensagem."""
    url_match = re.search(r'(https?://[^\s]+)', message)
    if url_match:
        return {"url_anuncio": url_match.group(1)}
    
    raise HTTPException(status_code=400, detail="Nenhuma URL encontrada na mensagem.")

# 2锔  Detecta o site de origem

@app.get("/detect-site/")
async def detect_site(url: str):
    match = re.search(r"https?://(?:www\.)?([^/]+)", url)
    if match:
        return {"site_detectado": match.group(1)}
    raise HTTPException(status_code=400, detail="URL inv谩lida.")

# 3锔  Extrai c贸digo do im贸vel e captura HTML automaticamente com Selenium

@app.get("/extract-code/")
async def extract_property_code(url: str, site: str):

    """Captura o HTML da p谩gina e extrai o c贸digo do im贸vel."""
    
    #  1锔 Captura o HTML usando Selenium

    html = fetch_html_with_selenium(url)

    soup = BeautifulSoup(html, "html.parser")

    #  2锔 Identifica o site antes de extrair o c贸digo

    site = site
    property_code = None

    if "imovelweb.com.br" in site:
        match = re.search(r'publisher_house_id\s*=\s*"([\w-]+)"', html)
        property_code = match.group(1) if match else None
    elif "chavesnamao.com.br" in site:
        match = re.search(r'Ref:\s*<!--\s*-->\s*([\w-]+)', html)
        property_code = match.group(1) if match else None
    elif "buscacuritiba.com.br" in site:
        reference_element = soup.find("p", string=re.compile("Refer锚ncia:", re.IGNORECASE))
        if reference_element:
            strong_tag = reference_element.find("strong")
            property_code = strong_tag.text.strip() if strong_tag else None
    else:
        match = re.search(r'(ID[:.\s]*\d+|C贸digo[:.\s]*\d+|ref[:.\s]*\d+)', html)
        property_code = match.group(1) if match else None

    if not property_code:
        raise HTTPException(status_code=404, detail="C贸digo do im贸vel n茫o encontrado no HTML.")

    return {"codigo_imovel": property_code}

# 4锔  Busca informa莽玫es do im贸vel no XML

@app.get("/fetch-xml/")
async def fetch_property_info(property_code: str):
    """Busca informa莽玫es do im贸vel no XML usando o c贸digo do im贸vel."""
    
    try:
        response = httpx.get(XML_URL)
        if response.status_code != 200:
            raise HTTPException(status_code=response.status_code, detail="Erro ao acessar XML.")

        soup = BeautifulSoup(response.text, "xml")

        property_info = soup.find("ListingID", string=property_code)
        if not property_info:
            raise HTTPException(status_code=404, detail="Im贸vel n茫o encontrado no XML.")

        return {"codigo_imovel": property_code}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

#  Fun莽茫o interna para buscar HTML com Selenium (agora chamada dentro de /extract-code/)

def fetch_html_with_selenium(url: str) -> str:
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option("useAutomationExtension", False)

    # Adiciona User-Agent realista
    options.add_argument(
        "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36"
    )

    service = ChromeService(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)

try:

    driver.get(url)
    html = driver.page_source

    # Verifica se houve bloqueio
    if "Acesso negado" in html or "Verifique que voc锚 n茫o 茅 um rob么" in html:
        raise HTTPException(status_code=403, detail="O site bloqueou o acesso via Selenium.")

    # Salva o HTML localmente para reutiliza莽茫o
        with open("pagina.html", "w", encoding="utf-8") as f:
            f.write(html)

        return html  # Retorna o HTML capturado

    except Exception as e:
        print(f"Erro ao capturar HTML: {e}")
        return ""

    finally:
        driver.quit()  # Fecha o navegador para evitar processos em aberto

